{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrupam/BERT_sentence_classification/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Nihl0cmh_e",
        "colab_type": "text"
      },
      "source": [
        "Following  [this]( https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784) blog for sentence classification using a pretrained BERT model, with multiclass, instead of binary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3vg4xdi-h3h",
        "colab_type": "code",
        "outputId": "46dd5cd9-b0a8-421e-e542-46338b9d5f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_oXjrFC_-BG",
        "colab_type": "code",
        "outputId": "46310e8f-19ad-49f2-91cb-f37db2fd0420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "% cd drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkPd7Kk6Ainl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from random import randrange\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxBm6BTgATeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATASET_COLUMNS = ['target','ids','date','flag','user', 'text']\n",
        "data = pd.read_csv('train.tsv',delimiter='\\t',encoding='utf-8', nrows=10000)#, encoding =\"ISO-8859-1\" , names=DATASET_COLUMNS, nrows=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvvhUlPDAVQX",
        "colab_type": "code",
        "outputId": "7756f041-6d66-47ef-b023-1c4795e2f6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xUDKnnlbpQ7",
        "colab_type": "code",
        "outputId": "b95aabae-b1a6-432d-bad6-36866b8a7fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data['Sentiment'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcrahbwObsNU",
        "colab_type": "code",
        "outputId": "383a6c5b-c8ed-46a9-fff6-093980c5933c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "data['Sentiment'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c18cd6fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEu5JREFUeJzt3X+MXWWdx/H3VwpCqEtR2Nmm7W7Z\n2OwGZUWYlBo3mwEiFDCUZNHUsFIIpskuZjVLomDiEhESTERc2FXTSGNx0UJQt92KyzalE+Mf/Kog\n5YcsI9alTaUrLdURZFP97h/3KXtTZ3rvnTv3R3ner2Qy5zznOfd8zzNz5nPPuefeicxEklSfNw26\nAEnSYBgAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpErNGXQBh3PSSSfl4sWLZ7z+\nr3/9a44//vjZK2iWWFdnrKsz1tWZN2Jd27Zt+0VmntyyY2YO7deZZ56Z3di6dWtX6/eKdXXGujpj\nXZ15I9YFPJpt/I31EpAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFVqqD8K\nQhpm23ft54prv9v37e64+aK+b1NvTJ4BSFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNA\nkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqVFsBEBE7ImJ7\nRDweEY+WtrdGxOaIeK58P7G0R0TcFhETEfFERJzR9DirSv/nImJVb3ZJktSOTs4Azs7M0zNztMxf\nC2zJzCXAljIPcAGwpHytBr4MjcAArgfOApYC1x8MDUlS/3VzCWgFsK5MrwMuaWq/MxseBOZFxHzg\nfGBzZu7NzH3AZmB5F9uXJHWh3QBI4D8jYltErC5tI5m5u0z/HBgp0wuAF5rW3VnapmuXJA3AnDb7\n/WVm7oqIPwQ2R8SPmxdmZkZEzkZBJWBWA4yMjDA+Pj7jx5qcnOxq/V6xrs4Ma10jx8E1px3o+3Zb\njcWwjpd1daYfdbUVAJm5q3zfExHfoXEN/8WImJ+Zu8slnj2l+y5gUdPqC0vbLmDskPbxKba1BlgD\nMDo6mmNjY4d2adv4+DjdrN8r1tWZYa3r9rs2cMv2dp9DzZ4dl40ddvmwjpd1daYfdbW8BBQRx0fE\nWw5OA+cBTwIbgYN38qwCNpTpjcDl5W6gZcD+cqnofuC8iDixvPh7XmmTJA1AO09fRoDvRMTB/t/I\nzP+IiEeAeyLiKuBnwAdL//uAC4EJ4BXgSoDM3BsRnwUeKf1uyMy9s7YnkqSOtAyAzHweeNcU7S8B\n507RnsDV0zzWWmBt52VKkmab7wSWpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoA\nkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJ\nqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpdoOgIg4KiIei4hNZf6UiHgoIiYi4u6I\nOKa0v7nMT5Tli5se47rS/mxEnD/bOyNJal8nZwAfA55pmv8ccGtmvh3YB1xV2q8C9pX2W0s/IuJU\nYCXwDmA58KWIOKq78iVJM9VWAETEQuAi4KtlPoBzgHtLl3XAJWV6RZmnLD+39F8BrM/M1zLzp8AE\nsHQ2dkKS1Ll2zwC+CHwC+F2ZfxvwcmYeKPM7gQVlegHwAkBZvr/0f719inUkSX02p1WHiHg/sCcz\nt0XEWK8LiojVwGqAkZERxsfHZ/xYk5OTXa3fK9bVmWGta+Q4uOa0A607zrJWYzGs42VdnelHXS0D\nAHgvcHFEXAgcC/wB8E/AvIiYU57lLwR2lf67gEXAzoiYA5wAvNTUflDzOq/LzDXAGoDR0dEcGxub\nwW41jI+P0836vWJdnRnWum6/awO3bG/nEJpdOy4bO+zyYR0v6+pMP+pqeQkoM6/LzIWZuZjGi7gP\nZOZlwFbg0tJtFbChTG8s85TlD2RmlvaV5S6hU4AlwMOztieSpI508/Tlk8D6iLgReAy4o7TfAXw9\nIiaAvTRCg8x8KiLuAZ4GDgBXZ+Zvu9i+JKkLHQVAZo4D42X6eaa4iyczfwN8YJr1bwJu6rRISdLs\n853AklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqU\nASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkA\nklQpA0CSKmUASFKlDABJqlTLAIiIYyPi4Yj4UUQ8FRGfKe2nRMRDETEREXdHxDGl/c1lfqIsX9z0\nWNeV9mcj4vxe7ZQkqbV2zgBeA87JzHcBpwPLI2IZ8Dng1sx8O7APuKr0vwrYV9pvLf2IiFOBlcA7\ngOXAlyLiqNncGUlS+1oGQDZMltmjy1cC5wD3lvZ1wCVlekWZpyw/NyKitK/PzNcy86fABLB0VvZC\nktSxtl4DiIijIuJxYA+wGfgJ8HJmHihddgILyvQC4AWAsnw/8Lbm9inWkST12Zx2OmXmb4HTI2Ie\n8B3gz3tVUESsBlYDjIyMMD4+PuPHmpyc7Gr9XrGuzgxrXSPHwTWnHWjdcZa1GothHS/r6kw/6mor\nAA7KzJcjYivwHmBeRMwpz/IXArtKt13AImBnRMwBTgBeamo/qHmd5m2sAdYAjI6O5tjYWEc71Gx8\nfJxu1u8V6+rMsNZ1+10buGV7R4fQrNhx2dhhlw/reFlXZ/pRVzt3AZ1cnvkTEccB7wOeAbYCl5Zu\nq4ANZXpjmacsfyAzs7SvLHcJnQIsAR6erR2RJHWmnacv84F15Y6dNwH3ZOamiHgaWB8RNwKPAXeU\n/ncAX4+ICWAvjTt/yMynIuIe4GngAHB1ubQkSRqAlgGQmU8A756i/XmmuIsnM38DfGCax7oJuKnz\nMiVJs813AktSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUy\nACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNA\nkiplAEhSpQwASaqUASBJlTIAJKlSLQMgIhZFxNaIeDoinoqIj5X2t0bE5oh4rnw/sbRHRNwWERMR\n8UREnNH0WKtK/+ciYlXvdkuS1Eo7ZwAHgGsy81RgGXB1RJwKXAtsycwlwJYyD3ABsKR8rQa+DI3A\nAK4HzgKWAtcfDA1JUv+1DIDM3J2ZPyzTvwKeARYAK4B1pds64JIyvQK4MxseBOZFxHzgfGBzZu7N\nzH3AZmD5rO6NJKltkZntd45YDHwfeCfw35k5r7QHsC8z50XEJuDmzPxBWbYF+CQwBhybmTeW9k8D\nr2bm5w/ZxmoaZw6MjIycuX79+hnv3OTkJHPnzp3x+r1iXZ0Z1rr27N3Pi6/2f7unLTjhsMuHdbys\nqzPd1HX22Wdvy8zRVv3mtPuAETEX+Bbw8cz8ZeNvfkNmZkS0nySHkZlrgDUAo6OjOTY2NuPHGh8f\np5v1e8W6OjOsdd1+1wZu2d72ITRrdlw2dtjlwzpe1tWZftTV1l1AEXE0jT/+d2Xmt0vzi+XSDuX7\nntK+C1jUtPrC0jZduyRpANq5CyiAO4BnMvMLTYs2Agfv5FkFbGhqv7zcDbQM2J+Zu4H7gfMi4sTy\n4u95pU2SNADtnL++F/gwsD0iHi9tnwJuBu6JiKuAnwEfLMvuAy4EJoBXgCsBMnNvRHwWeKT0uyEz\n987KXkiSOtYyAMqLuTHN4nOn6J/A1dM81lpgbScFShoei6/97ozXvea0A1wxw/V33HzRjLer6flO\nYEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKl+v9JVuqZbt6kA75RR6qNZwCSVCkD\nQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAk\nqVIGgCRVygCQpEoZAJJUKQNAkirVMgAiYm1E7ImIJ5va3hoRmyPiufL9xNIeEXFbRExExBMRcUbT\nOqtK/+ciYlVvdkeS1K52zgC+Biw/pO1aYEtmLgG2lHmAC4Al5Ws18GVoBAZwPXAWsBS4/mBoSJIG\no2UAZOb3gb2HNK8A1pXpdcAlTe13ZsODwLyImA+cD2zOzL2ZuQ/YzO+HiiSpj2b6GsBIZu4u0z8H\nRsr0AuCFpn47S9t07ZKkAYnMbN0pYjGwKTPfWeZfzsx5Tcv3ZeaJEbEJuDkzf1DatwCfBMaAYzPz\nxtL+aeDVzPz8FNtaTePyESMjI2euX79+xjs3OTnJ3LlzZ7x+r/Sqru279ne1/shx8OKrM1v3tAUn\ndLXtwxnWn+OevftnPF7daDXWvRyvbn7H/P3qTDd1nX322dsyc7RVvzkzenR4MSLmZ+bucolnT2nf\nBSxq6rewtO2iEQLN7eNTPXBmrgHWAIyOjubY2NhU3doyPj5ON+v3Sq/quuLa73a1/jWnHeCW7TP7\nldhx2VhX2z6cYf053n7XhhmPVzdajXUvx6ub3zF/vzrTj7pmegloI3DwTp5VwIam9svL3UDLgP3l\nUtH9wHkRcWJ58fe80iZJGpCWcRwR36Tx7P2kiNhJ426em4F7IuIq4GfAB0v3+4ALgQngFeBKgMzc\nGxGfBR4p/W7IzENfWJYk9VHLAMjMD02z6Nwp+iZw9TSPsxZY21F1kqSe8Z3AklQpA0CSKmUASFKl\nDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlS/f93RpJ0\nhFjc5X/Z68bXlh/f8214BiBJlTIAJKlSBoAkVeoN/RrA9l37uWIA1/B23HxR37cpSZ3yDECSKmUA\nSFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkirV9wCIiOUR8WxETETEtf3eviSpoa8B\nEBFHAf8CXACcCnwoIk7tZw2SpIZ+nwEsBSYy8/nM/F9gPbCizzVIkuh/ACwAXmia31naJEl9FpnZ\nv41FXAosz8yPlPkPA2dl5keb+qwGVpfZPwOe7WKTJwG/6GL9XrGuzlhXZ6yrM2/Euv4kM09u1anf\nHwe9C1jUNL+wtL0uM9cAa2ZjYxHxaGaOzsZjzSbr6ox1dca6OlNzXf2+BPQIsCQiTomIY4CVwMY+\n1yBJos9nAJl5ICI+CtwPHAWszcyn+lmDJKmh7/8RLDPvA+7r0+Zm5VJSD1hXZ6yrM9bVmWrr6uuL\nwJKk4eFHQUhSpY74AGj10RIR8eaIuLssfygiFg9JXVdExP9ExOPl6yN9qmttROyJiCenWR4RcVup\n+4mIOGNI6hqLiP1N4/WPfaprUURsjYinI+KpiPjYFH36PmZt1tX3MYuIYyPi4Yj4UanrM1P06fsx\n2WZdgzomj4qIxyJi0xTLejtWmXnEftF4IfknwJ8CxwA/Ak49pM/fAV8p0yuBu4ekriuAfx7AmP0V\ncAbw5DTLLwS+BwSwDHhoSOoaAzYNYLzmA2eU6bcA/zXFz7LvY9ZmXX0fszIGc8v00cBDwLJD+gzi\nmGynrkEdk/8AfGOqn1Wvx+pIPwNo56MlVgDryvS9wLkREUNQ10Bk5veBvYfpsgK4MxseBOZFxPwh\nqGsgMnN3Zv6wTP8KeIbff/d638eszbr6rozBZJk9unwd+kJj34/JNuvqu4hYCFwEfHWaLj0dqyM9\nANr5aInX+2TmAWA/8LYhqAvgr8slg3sjYtEUywdhmD+u4z3lFP57EfGOfm+8nH6/m8azx2YDHbPD\n1AUDGLNySeNxYA+wOTOnHa8+HpPt1AX9Pya/CHwC+N00y3s6Vkd6ABzJ/h1YnJl/AWzm/1NeU/sh\njbe3vwu4Hfi3fm48IuYC3wI+npm/7Oe2D6dFXQMZs8z8bWaeTuOd/ksj4p392G4rbdTV12MyIt4P\n7MnMbb3czuEc6QHQ8qMlmvtExBzgBOClQdeVmS9l5mtl9qvAmT2uqV3tjGnfZeYvD57CZ+O9JEdH\nxEn92HZEHE3jj+xdmfntKboMZMxa1TXIMSvbfBnYCiw/ZNEgjsmWdQ3gmHwvcHFE7KBxmficiPjX\nQ/r0dKyO9ABo56MlNgKryvSlwANZXlEZZF2HXCO+mMY13GGwEbi83NmyDNifmbsHXVRE/NHBa58R\nsZTG727P/2iUbd4BPJOZX5imW9/HrJ26BjFmEXFyRMwr08cB7wN+fEi3vh+T7dTV72MyM6/LzIWZ\nuZjG34gHMvNvDunW07Hq+zuBZ1NO89ESEXED8GhmbqRxkHw9IiZovMi4ckjq+vuIuBg4UOq6otd1\nAUTEN2ncHXJSROwErqfxghiZ+RUa79K+EJgAXgGuHJK6LgX+NiIOAK8CK/sQ5NB4lvZhYHu5fgzw\nKeCPm2obxJi1U9cgxmw+sC4a//zpTcA9mblp0Mdkm3UN5Jg8VD/HyncCS1KljvRLQJKkGTIAJKlS\nBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmq1P8BiPt5DnuEUAUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRiflTqeBs25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "package_dir = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
        "sys.path.append(package_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4V2DKqnAds",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2Js9GxFChQ",
        "colab_type": "code",
        "outputId": "680f9fff-0437-4789-87d5-c3a2df4caf59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.189)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Collecting regex (from pytorch-pretrained-bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.13.0,>=1.12.189 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.189)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.189->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qHFNX5FEUA",
        "colab_type": "code",
        "outputId": "a512c2c8-c4ce-4705-a40f-1d0f50761b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "#import pytorch_pretrained_bert\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertForMaskedLM\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5)\n",
        "\n",
        "warnings.filterwarnings(action='once')\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:38<00:00, 10628277.61B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3doMeMFITS",
        "colab_type": "code",
        "outputId": "85a2c2d2-3156-4e55-d56c-379c3ab074e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 917924.04B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXDIJUHYH7pW",
        "colab_type": "code",
        "outputId": "b012c96b-6742-45c5-c5f0-311141a44869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#sentiment_columns = ['Negative','Somewhat Negative','Neutral','Somewhat Positive', 'Positive']\n",
        "X = data['Phrase']\n",
        "y = data['Sentiment']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlIJ9PAxIe3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.values.tolist()\n",
        "X_test = X_test.values.tolist()\n",
        "\n",
        "y_train = pd.get_dummies(y_train).values.tolist()\n",
        "y_test = pd.get_dummies(y_test).values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6t5TOCnKCc",
        "colab_type": "text"
      },
      "source": [
        "Now we create a class to preprocess data that involves tokenizing, truncating and padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8xKgazJ29_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "class text_dataset(Dataset):\n",
        "    def __init__(self,x_y_list, transform=None):\n",
        "        \n",
        "        self.x_y_list = x_y_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
        "        \n",
        "        if len(tokenized_review) > max_seq_length:\n",
        "            tokenized_review = tokenized_review[:max_seq_length]\n",
        "            \n",
        "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(ids_review))\n",
        "        \n",
        "        ids_review += padding\n",
        "        \n",
        "        assert len(ids_review) == max_seq_length\n",
        "        \n",
        "        #print(\"Hello\")\n",
        "        ids_review = torch.tensor(ids_review)\n",
        "        \n",
        "        sentiment = self.x_y_list[1][index] # color        \n",
        "        list_of_labels = [torch.from_numpy(np.array(sentiment))]\n",
        "        \n",
        "        \n",
        "        return ids_review, list_of_labels[0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_y_list[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQrQTCRrnZXt",
        "colab_type": "text"
      },
      "source": [
        "Preparing and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA3U816YksO_",
        "colab_type": "code",
        "outputId": "8a094b60-0bdb-4ba4-e983-c69cae6b4e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_lists = [X_train, y_train]\n",
        "test_lists = [X_test, y_test]\n",
        "\n",
        "training_dataset = text_dataset(x_y_list = train_lists )\n",
        "\n",
        "test_dataset = text_dataset(x_y_list = test_lists )\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "                   }\n",
        "dataset_sizes = {'train':len(train_lists[0]),\n",
        "                'val':len(test_lists[0])}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVep1AogIndK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "        \n",
        "\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller\n",
        "            than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, num_labels=5):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBh7tlgI1it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 5\n",
        "model = BertForSequenceClassification(num_labels)\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n",
        "\n",
        "#logits = model(tokens_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7B4rLMnFR4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    print('starting')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            sentiment_corrects = 0\n",
        "            \n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, sentiment in dataloaders_dict[phase]:\n",
        "                #print(\"ok till here\")\n",
        "                #inputs = inputs\n",
        "                #print(len(inputs),type(inputs),inputs)\n",
        "                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n",
        "                inputs = inputs.to(device) \n",
        "\n",
        "                sentiment = sentiment.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        " \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #print(inputs)\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    outputs = F.softmax(outputs,dim = 1)\n",
        "                    \n",
        "                    loss = criterion(outputs, torch.max(sentiment.float(), 1)[1])\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                \n",
        "                sentiment_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(sentiment, 1)[1])\n",
        "\n",
        "                \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            \n",
        "            sentiment_acc = sentiment_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
        "            print('{} sentiment_acc: {:.4f}'.format(\n",
        "                phase, sentiment_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print('saving with loss of {}'.format(epoch_loss),\n",
        "                      'improved over previous {}'.format(best_loss))\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDoE-BzSH41N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "optim1 = optim.Adam(\n",
        "    [\n",
        "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
        "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
        "       \n",
        "   ])\n",
        "\n",
        "#optim1 = optim.Adam(model.parameters(), lr=0.001)#,momentum=.9)\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKcj7f5J0KM",
        "colab_type": "code",
        "outputId": "522c0eed-c95e-49e5-d1ce-d9f36f46cf2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "model.to(device)\n",
        "model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "Epoch 0/9\n",
            "----------\n",
            "train total loss: 1.3417 \n",
            "train sentiment_acc: 0.5636\n",
            "val total loss: 1.3438 \n",
            "val sentiment_acc: 0.5610\n",
            "saving with loss of 1.3438354759216309 improved over previous 100\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train total loss: 1.3407 \n",
            "train sentiment_acc: 0.5641\n",
            "val total loss: 1.3438 \n",
            "val sentiment_acc: 0.5610\n",
            "saving with loss of 1.343833745956421 improved over previous 1.3438354759216309\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-103b55d423bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 3\u001b[0;31m                        num_epochs=10)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-fb48e59dc731>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67OKez2ecjDg",
        "colab_type": "text"
      },
      "source": [
        "# **TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sP_L6Hz_ybT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test = pd.read_csv('test.tsv',delimiter='\\t',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HtiKvQOAAUZ",
        "colab_type": "code",
        "outputId": "b01fb4f0-c18d-49b7-ace1-bfd106263bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7gzFXvMeSC8",
        "colab_type": "text"
      },
      "source": [
        "Pick out the data and put it in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3hPeK3hAQ1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_final_test = final_test['Phrase']\n",
        "X_final_test = X_final_test.values.tolist()\n",
        "#print(X_final_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7TJU0QQeYxL",
        "colab_type": "text"
      },
      "source": [
        "Define a function to preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvT8bf2OtU_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "reviews=[]\n",
        "def test_dataset(Dataset):\n",
        "    for i in range(0,len(Dataset)):\n",
        "      tokenized_review = tokenizer.tokenize(Dataset[i])\n",
        "\n",
        "      if len(tokenized_review) > max_seq_length:\n",
        "          tokenized_review = tokenized_review[:max_seq_length]\n",
        "\n",
        "      ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "      padding = [0] * (max_seq_length - len(ids_review))\n",
        "\n",
        "      ids_review += padding\n",
        "\n",
        "      assert len(ids_review) == max_seq_length\n",
        "\n",
        "      #print(\"Hello\")\n",
        "      reviews.append(ids_review)\n",
        "\n",
        "    #sentiment = self.x_y_list[1][index] # color        \n",
        "    #list_of_labels = [torch.from_numpy(np.array(sentiment))]\n",
        "\n",
        "\n",
        "    return reviews#, list_of_labels[0]\n",
        "\n",
        "#def __len__(self):\n",
        " #   return len(self.x_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey1cP-laejpm",
        "colab_type": "text"
      },
      "source": [
        "Call the function to preprocess the data on our list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g39ojueuEeFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "96d4e3bf-c52d-43fa-a1e9-65d5de3e8dc1"
      },
      "source": [
        "X_final_test = test_dataset(X_final_test)\n",
        "#print(X_final_test)\n",
        "#test_dataset(X_final_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4199e6897e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_final_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_final_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(X_final_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#test_dataset(X_final_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-ad5a83f9f203>\u001b[0m in \u001b[0;36mtest_dataset\u001b[0;34m(Dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mtokenized_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_review\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc5BXD-eun9",
        "colab_type": "text"
      },
      "source": [
        "Define the model and the configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_REsL6c4Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 5\n",
        "model = BertForSequenceClassification(num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBCAQx5qe2Tn",
        "colab_type": "text"
      },
      "source": [
        "Load the model, trained on our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMvX5ChbEOc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from pytorch_pretrained_bert import BertConfig\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5)\n",
        "model.load_state_dict(torch.load('bert_model_test.pth'))\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUYt2GnCfBUH",
        "colab_type": "text"
      },
      "source": [
        "Run our test list through the model and write the results to a file called test_preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej3sPWTDFv60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()\n",
        "test_preds = np.zeros((len(final_test),5))\n",
        "tests =  torch.utils.data.TensorDataset(torch.tensor(X_final_test))#,dtype=torch.long)) \n",
        "#tests =  torch.utils.data.DataLoader(X_final_test, batch_size=16, shuffle=True, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(tests, batch_size=16, shuffle=False)\n",
        "\n",
        "#tk0 = tqdm_notebook(test_loader)\n",
        "\n",
        "for i,(x_batch,)  in enumerate(test_loader):\n",
        "    t_preds = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    test_preds[i*16:(i+1)*16]=t_preds[:,0:5].detach().cpu().squeeze().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxACSX5KhFb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_p = pd.DataFrame(test_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA5HOjYWhXtQ",
        "colab_type": "code",
        "outputId": "35909870-5bca-49aa-f67e-77d2e5ff15ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "t_p.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.643804</td>\n",
              "      <td>-1.892407</td>\n",
              "      <td>3.386405</td>\n",
              "      <td>-2.001749</td>\n",
              "      <td>-3.506268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.006383</td>\n",
              "      <td>-0.785386</td>\n",
              "      <td>1.779258</td>\n",
              "      <td>-0.790580</td>\n",
              "      <td>-0.163048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.584310</td>\n",
              "      <td>-1.501119</td>\n",
              "      <td>3.794366</td>\n",
              "      <td>-2.792164</td>\n",
              "      <td>-2.499760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.001685</td>\n",
              "      <td>-1.462754</td>\n",
              "      <td>2.705199</td>\n",
              "      <td>-1.084235</td>\n",
              "      <td>-1.727064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.145345</td>\n",
              "      <td>-1.398572</td>\n",
              "      <td>2.399182</td>\n",
              "      <td>-0.931489</td>\n",
              "      <td>-1.999005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4\n",
              "0 -2.643804 -1.892407  3.386405 -2.001749 -3.506268\n",
              "1 -1.006383 -0.785386  1.779258 -0.790580 -0.163048\n",
              "2 -2.584310 -1.501119  3.794366 -2.792164 -2.499760\n",
              "3 -2.001685 -1.462754  2.705199 -1.084235 -1.727064\n",
              "4 -2.145345 -1.398572  2.399182 -0.931489 -1.999005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avd3Ag_HfifF",
        "colab_type": "text"
      },
      "source": [
        "Define a softmax function for our predictions (so we get a probability distribution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YANaL0t0foAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNT2-DYUDdVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds1 = t_p.apply(lambda x:softmax(x), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQHzO45lUCdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_preds1).to_csv(\"test_preds1.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duviFKynUUTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}