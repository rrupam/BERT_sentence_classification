{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Alexis_Modified_Annotation_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "3Q-9v0WxgFGC",
        "xZ-H8Y_lgmol",
        "fqx1f3HviLe6",
        "9i4V2DKqnAds",
        "7w5K5SN0AwHc",
        "qUL5uFF5c_05",
        "67OKez2ecjDg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrupam/BERT_sentence_classification/blob/master/BERT_Alexis_Modified_Annotation_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Nihl0cmh_e",
        "colab_type": "text"
      },
      "source": [
        "Thanks to Huggingface's pytorch implementation of BERT. [Here](https://github.com/huggingface/pytorch-transformers) is the link to their library.\n",
        "\n",
        "Following  [this]( https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784) blog for sentence classification using a pretrained BERT model, with multiclass, instead of binary. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3vg4xdi-h3h",
        "colab_type": "code",
        "outputId": "a6a637a3-0442-4eef-a6fc-af4e7966a95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_oXjrFC_-BG",
        "colab_type": "code",
        "outputId": "38e32a34-1341-49aa-b3af-e2e56864c6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "% cd drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis'\n",
            "/content/drive/My Drive/Colab Notebooks/PTSD/Sentiment_Analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkPd7Kk6Ainl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from random import randrange\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxBm6BTgATeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('PTSD_data_Colton_Alexis_final.csv', nrows = 865)# limiting the number of rows to only the text that has already been annotated by Alexis\n",
        "#,delimiter='\\t',encoding='utf-8', nrows=10000)#, encoding =\"ISO-8859-1\" , names=DATASET_COLUMNS, nrows=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "torgXT4W8z2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = pd.read_csv('PTSD_data_Colton_Alexis_final.csv',  skiprows=3)\n",
        "raw_annotations = pd.read_csv(\"PTSD_data_conversation_annotation_final.csv\", skiprows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvvhUlPDAVQX",
        "colab_type": "code",
        "outputId": "1ff158f9-9021-4873-a03c-078ed01735ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>character</th>\n",
              "      <th>text</th>\n",
              "      <th>Keywords / Significant sentences</th>\n",
              "      <th>A1</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B5</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>E1</th>\n",
              "      <th>E2</th>\n",
              "      <th>E3</th>\n",
              "      <th>E4</th>\n",
              "      <th>E5</th>\n",
              "      <th>E6</th>\n",
              "      <th>F1</th>\n",
              "      <th>G1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>THERAPIST</td>\n",
              "      <td>Those darn women.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>Damn women. Our boss is she's just a shut the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>THERAPIST</td>\n",
              "      <td>It's not that comfortable.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>CLIENT</td>\n",
              "      <td>What's that?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id  character  ...   F1   G1\n",
              "0   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "1   PTSD_file_1  THERAPIST  ...  0.0  0.0\n",
              "2   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "3   PTSD_file_1  THERAPIST  ...  0.0  0.0\n",
              "4   PTSD_file_1     CLIENT  ...  0.0  0.0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEgPbi9M9xAe",
        "colab_type": "code",
        "outputId": "c9a4993f-df00-45d2-cd99-cd40cd37a7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scorer</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>G</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  Scorer    A    B    C    D    E    G\n",
              "0  PTSD_file_1  Alexis  1.0  0.0  1.0  1.0  0.0  0.0\n",
              "1  PTSD_file_2  Alexis  1.0  1.0  1.0  1.0  1.0  0.0\n",
              "2  PTSD_file_3  Alexis  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  PTSD_file_4  Alexis  0.0  1.0  1.0  1.0  1.0  0.0\n",
              "4  PTSD_file_5  Alexis  1.0  0.0  0.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsufUCJa93_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_text_combined = raw_data.groupby(\"transcript_id\")[\"text\"].agg(lambda col: ' '.join(col))\n",
        "text_transcript_combined = raw_text_combined.to_frame()\n",
        "text_transcript_combined.reset_index(level=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz4zvfSc97vH",
        "colab_type": "code",
        "outputId": "b4afef4a-b355-4dc4-d38b-05afe4320107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text_transcript_combined.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_10</td>\n",
              "      <td>The arch. How was time?  Good, good, thanks. Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_11</td>\n",
              "      <td>(yawning) Hi. Hi.  I don’t know why I can’t ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_12</td>\n",
              "      <td>Hi. Come on in. Morning. Morning. Is it less c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_13</td>\n",
              "      <td>(inaudible response)  Thanks for not having (i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id                                               text\n",
              "0   PTSD_file_1  Remind me never to go to a work meeting with a...\n",
              "1  PTSD_file_10  The arch. How was time?  Good, good, thanks. Y...\n",
              "2  PTSD_file_11  (yawning) Hi. Hi.  I don’t know why I can’t ge...\n",
              "3  PTSD_file_12  Hi. Come on in. Morning. Morning. Is it less c...\n",
              "4  PTSD_file_13  (inaudible response)  Thanks for not having (i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfsvKhaaMZ-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_transcript_combined.to_csv(\"transcripts_original.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cg1N7Or-BMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_annotations[\"label\"] = (raw_annotations[\"A\"]+raw_annotations[\"B\"]+raw_annotations[\"C\"]+raw_annotations[\"D\"]+raw_annotations[\"E\"]+raw_annotations[\"G\"])/6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZDrRi0Z-OPN",
        "colab_type": "code",
        "outputId": "d7899dbe-49a4-438a-8338-007a5e264f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scorer</th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>G</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>Alexis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  Scorer    A    B    C    D    E    G     label\n",
              "0  PTSD_file_1  Alexis  1.0  0.0  1.0  1.0  0.0  0.0  0.500000\n",
              "1  PTSD_file_2  Alexis  1.0  1.0  1.0  1.0  1.0  0.0  0.833333\n",
              "2  PTSD_file_3  Alexis  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3  PTSD_file_4  Alexis  0.0  1.0  1.0  1.0  1.0  0.0  0.666667\n",
              "4  PTSD_file_5  Alexis  1.0  0.0  0.0  0.0  0.0  0.0  0.166667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DM2ZuQa-X_C",
        "colab_type": "code",
        "outputId": "87f368c0-161b-4ae7-f7d3-9367a7496ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_annotations = raw_annotations.round({\"label\":0})[[\"Session_id\",\"label\"]]\n",
        "final_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Session_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Session_id  label\n",
              "0  PTSD_file_1    0.0\n",
              "1  PTSD_file_2    1.0\n",
              "2  PTSD_file_3    0.0\n",
              "3  PTSD_file_4    1.0\n",
              "4  PTSD_file_5    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXO1DejQ-eub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_annotations = final_annotations.rename(columns = {\"Session_id\": \"transcript_id\"}) \n",
        "final_annotations.label = final_annotations.label.fillna(0)\n",
        "final_annotations.label = final_annotations.label.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTHyT8H-esN",
        "colab_type": "code",
        "outputId": "00424286-0a8b-4bcf-dc9a-9e1bfc75d9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_annotations.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id  label\n",
              "0   PTSD_file_1      0\n",
              "1   PTSD_file_2      1\n",
              "2   PTSD_file_3      0\n",
              "3   PTSD_file_4      1\n",
              "4   PTSD_file_5      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie9DIL_D-ONF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_dataset = pd.merge(text_transcript_combined, final_annotations, on='transcript_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa_fQ8Uu-733",
        "colab_type": "code",
        "outputId": "2d0c12bd-2de6-4b8a-fee4-3f0ad8c79034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "final_dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_10</td>\n",
              "      <td>The arch. How was time?  Good, good, thanks. Y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_11</td>\n",
              "      <td>(yawning) Hi. Hi.  I don’t know why I can’t ge...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_12</td>\n",
              "      <td>Hi. Come on in. Morning. Morning. Is it less c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_13</td>\n",
              "      <td>(inaudible response)  Thanks for not having (i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id                                               text  label\n",
              "0   PTSD_file_1  Remind me never to go to a work meeting with a...      0\n",
              "1  PTSD_file_10  The arch. How was time?  Good, good, thanks. Y...      1\n",
              "2  PTSD_file_11  (yawning) Hi. Hi.  I don’t know why I can’t ge...      1\n",
              "3  PTSD_file_12  Hi. Come on in. Morning. Morning. Is it less c...      0\n",
              "4  PTSD_file_13  (inaudible response)  Thanks for not having (i...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q-9v0WxgFGC",
        "colab_type": "text"
      },
      "source": [
        "## Adding backtranslations from different languages to increase our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgSnex58M2vT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_french_backtranslated = pd.read_csv('transcripts_French_backtranslation.csv')\n",
        "transcript_hindi_backtranslated = pd.read_csv('transcripts_Hindi_backtranslation.csv')\n",
        "transcript_french_backtranslated = transcript_french_backtranslated.drop(columns='Unnamed: 0')\n",
        "transcript_hindi_backtranslated = transcript_hindi_backtranslated.drop(columns='Unnamed: 0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2qTWhdNe3Lv",
        "colab_type": "code",
        "outputId": "350d2599-af80-49f0-a8f5-e66284119ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "transcript_hindi_backtranslated.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Please tell Chad the question mark. I will tel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>You owed last week. I do not know if you remem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>It sounds weird, but I feel a little tidy. I d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>So, sorry for Tuesday. Yes, it took us seven h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transcript_id                                               text\n",
              "0   PTSD_file_1  Remind me never to go to a work meeting with a...\n",
              "1   PTSD_file_2  Please tell Chad the question mark. I will tel...\n",
              "2   PTSD_file_3  You owed last week. I do not know if you remem...\n",
              "3   PTSD_file_4  It sounds weird, but I feel a little tidy. I d...\n",
              "4   PTSD_file_5  So, sorry for Tuesday. Yes, it took us seven h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV2oGGxqfVvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_french_backtranslated = pd.merge(transcript_french_backtranslated, final_annotations, on='transcript_id')\n",
        "dataset_hindi_backtranslated = pd.merge(transcript_hindi_backtranslated, final_annotations, on='transcript_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6UVhvLrhCHI",
        "colab_type": "text"
      },
      "source": [
        "Now join the original dataset from before with the new backtranslated datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6FvgNmhIxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_dataset = pd.concat([final_dataset, dataset_french_backtranslated, dataset_hindi_backtranslated], ignore_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTi7O811hcRe",
        "colab_type": "code",
        "outputId": "14dd77ce-c52f-4524-cd90-c40c002a7588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final_dataset.head(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a work meeting with a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PTSD_file_10</td>\n",
              "      <td>The arch. How was time?  Good, good, thanks. Y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PTSD_file_11</td>\n",
              "      <td>(yawning) Hi. Hi.  I don’t know why I can’t ge...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PTSD_file_12</td>\n",
              "      <td>Hi. Come on in. Morning. Morning. Is it less c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PTSD_file_13</td>\n",
              "      <td>(inaudible response)  Thanks for not having (i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PTSD_file_14</td>\n",
              "      <td>What's up? I just remembered when I was parkin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PTSD_file_15</td>\n",
              "      <td>What’s up? It’s nice and cool in here. It can ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PTSD_file_16</td>\n",
              "      <td>How’s it going? Feel better?  Much better, tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PTSD_file_17</td>\n",
              "      <td>I’m fighting a little hypochondria situation. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PTSD_file_18</td>\n",
              "      <td>I don't have a new bill for you yet. The insu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PTSD_file_19</td>\n",
              "      <td>You know, just paying you every week and what...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Tell Chad question mark. I will let you know l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PTSD_file_20</td>\n",
              "      <td>...wondering. Better safe than sorry. (sigh) T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PTSD_file_21</td>\n",
              "      <td>Did you see that article or that blog in the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PTSD_file_22</td>\n",
              "      <td>So this is for March as a running total, the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PTSD_file_23</td>\n",
              "      <td>I don’t know where you were with the accounti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>PTSD_file_24</td>\n",
              "      <td>Thanks for not making it hot in here. (laughs)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PTSD_file_25</td>\n",
              "      <td>When I called they said they couldn’t get a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>PTSD_file_26</td>\n",
              "      <td>...a little bit of worry thinking maybe all o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>PTSD_file_27</td>\n",
              "      <td>So I'm clear. You have new insurance but you d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>PTSD_file_28</td>\n",
              "      <td>Hi. Hi. You’re on time for once. What? You’re ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>PTSD_file_29</td>\n",
              "      <td>So, I guess transitioning to new medication i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PTSD_file_3</td>\n",
              "      <td>You owed from last week. I don't know if you r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>PTSD_file_30</td>\n",
              "      <td>Thanks. Yep. I don't know if that does that in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PTSD_file_31</td>\n",
              "      <td>Come on.  Yeah, how's it feel?  Feels awesome....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>PTSD_file_32</td>\n",
              "      <td>(inaudible). Wasn’t available that day, I thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>PTSD_file_33</td>\n",
              "      <td>You (ph) changed (inaudible) with. (clears thr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>PTSD_file_34</td>\n",
              "      <td>How are you?  Um, similar I guess. I'm just cu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>PTSD_file_35</td>\n",
              "      <td>Yes. We should figure out how to deal with th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>PTSD_file_36</td>\n",
              "      <td>(inaudible at 00:00:05) there is no particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>PTSD_file_37</td>\n",
              "      <td>How are you? Good. You got my message. Yes. Ok...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>PTSD_file_38</td>\n",
              "      <td>That was out in the hallway?  My hallway. I ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>PTSD_file_39</td>\n",
              "      <td>No, it's not locked.  Oh, my God. Carl. Not l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PTSD_file_4</td>\n",
              "      <td>This sounds odd, but I’m kind of feeling over...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PTSD_file_40</td>\n",
              "      <td>It’s cold out there. (laughs)  Yes. Mid-March,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PTSD_file_41</td>\n",
              "      <td>Not much has happened since Tuesday. Been bus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>PTSD_file_42</td>\n",
              "      <td>I've never seen the inside of the office when ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>PTSD_file_43</td>\n",
              "      <td>I’d like two beers and half a shot of whiskey...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>PTSD_file_44</td>\n",
              "      <td>We did it. Oh, man. I’m definitely anxious, e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>PTSD_file_45</td>\n",
              "      <td>The first one is I will be out the second hal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>PTSD_file_46</td>\n",
              "      <td>I still have not charged your card. I noticed....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>PTSD_file_47</td>\n",
              "      <td>I’m sorry. That’s okay. Go ahead and take your...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>PTSD_file_48</td>\n",
              "      <td>Well, let me tell you. Whoops, sorry. That wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>PTSD_file_5</td>\n",
              "      <td>So hey, sorry about Tuesday. Yeah, it ended u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>PTSD_file_6</td>\n",
              "      <td>Claire, [ph] can you wait on that? Like, I me...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>PTSD_file_7</td>\n",
              "      <td>Where are you?  I guess okay. I guess I felt m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>PTSD_file_8</td>\n",
              "      <td>One link I couldn’t click on for some reason,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>PTSD_file_9</td>\n",
              "      <td>That was an interesting association, how I mi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>PTSD_file_1</td>\n",
              "      <td>Remind me never to go to a meeting with a grou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>PTSD_file_2</td>\n",
              "      <td>Say to the question mark Chad. I'll let you kn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   transcript_id                                               text  label\n",
              "0    PTSD_file_1  Remind me never to go to a work meeting with a...      0\n",
              "1   PTSD_file_10  The arch. How was time?  Good, good, thanks. Y...      1\n",
              "2   PTSD_file_11  (yawning) Hi. Hi.  I don’t know why I can’t ge...      1\n",
              "3   PTSD_file_12  Hi. Come on in. Morning. Morning. Is it less c...      0\n",
              "4   PTSD_file_13  (inaudible response)  Thanks for not having (i...      1\n",
              "5   PTSD_file_14  What's up? I just remembered when I was parkin...      0\n",
              "6   PTSD_file_15  What’s up? It’s nice and cool in here. It can ...      0\n",
              "7   PTSD_file_16  How’s it going? Feel better?  Much better, tha...      1\n",
              "8   PTSD_file_17  I’m fighting a little hypochondria situation. ...      0\n",
              "9   PTSD_file_18   I don't have a new bill for you yet. The insu...      0\n",
              "10  PTSD_file_19   You know, just paying you every week and what...      0\n",
              "11   PTSD_file_2  Tell Chad question mark. I will let you know l...      1\n",
              "12  PTSD_file_20  ...wondering. Better safe than sorry. (sigh) T...      0\n",
              "13  PTSD_file_21   Did you see that article or that blog in the ...      0\n",
              "14  PTSD_file_22   So this is for March as a running total, the ...      1\n",
              "15  PTSD_file_23   I don’t know where you were with the accounti...      1\n",
              "16  PTSD_file_24  Thanks for not making it hot in here. (laughs)...      0\n",
              "17  PTSD_file_25   When I called they said they couldn’t get a c...      0\n",
              "18  PTSD_file_26   ...a little bit of worry thinking maybe all o...      0\n",
              "19  PTSD_file_27  So I'm clear. You have new insurance but you d...      0\n",
              "20  PTSD_file_28  Hi. Hi. You’re on time for once. What? You’re ...      0\n",
              "21  PTSD_file_29   So, I guess transitioning to new medication i...      0\n",
              "22   PTSD_file_3  You owed from last week. I don't know if you r...      0\n",
              "23  PTSD_file_30  Thanks. Yep. I don't know if that does that in...      0\n",
              "24  PTSD_file_31  Come on.  Yeah, how's it feel?  Feels awesome....      0\n",
              "25  PTSD_file_32   (inaudible). Wasn’t available that day, I thi...      0\n",
              "26  PTSD_file_33  You (ph) changed (inaudible) with. (clears thr...      0\n",
              "27  PTSD_file_34  How are you?  Um, similar I guess. I'm just cu...      0\n",
              "28  PTSD_file_35   Yes. We should figure out how to deal with th...      0\n",
              "29  PTSD_file_36   (inaudible at 00:00:05) there is no particula...      0\n",
              "30  PTSD_file_37  How are you? Good. You got my message. Yes. Ok...      0\n",
              "31  PTSD_file_38  That was out in the hallway?  My hallway. I ha...      0\n",
              "32  PTSD_file_39   No, it's not locked.  Oh, my God. Carl. Not l...      0\n",
              "33   PTSD_file_4   This sounds odd, but I’m kind of feeling over...      1\n",
              "34  PTSD_file_40  It’s cold out there. (laughs)  Yes. Mid-March,...      1\n",
              "35  PTSD_file_41   Not much has happened since Tuesday. Been bus...      0\n",
              "36  PTSD_file_42  I've never seen the inside of the office when ...      0\n",
              "37  PTSD_file_43   I’d like two beers and half a shot of whiskey...      0\n",
              "38  PTSD_file_44   We did it. Oh, man. I’m definitely anxious, e...      0\n",
              "39  PTSD_file_45   The first one is I will be out the second hal...      0\n",
              "40  PTSD_file_46  I still have not charged your card. I noticed....      0\n",
              "41  PTSD_file_47  I’m sorry. That’s okay. Go ahead and take your...      0\n",
              "42  PTSD_file_48   Well, let me tell you. Whoops, sorry. That wa...      0\n",
              "43   PTSD_file_5   So hey, sorry about Tuesday. Yeah, it ended u...      0\n",
              "44   PTSD_file_6   Claire, [ph] can you wait on that? Like, I me...      0\n",
              "45   PTSD_file_7  Where are you?  I guess okay. I guess I felt m...      1\n",
              "46   PTSD_file_8   One link I couldn’t click on for some reason,...      0\n",
              "47   PTSD_file_9   That was an interesting association, how I mi...      0\n",
              "48   PTSD_file_1  Remind me never to go to a meeting with a grou...      0\n",
              "49   PTSD_file_2  Say to the question mark Chad. I'll let you kn...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-H8Y_lgmol",
        "colab_type": "text"
      },
      "source": [
        "## Basic exploratory data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBypQTEvMMhF",
        "colab_type": "code",
        "outputId": "2034b89b-4d6b-4d96-9431-5a64b8cd4ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "final_dataset['label'].hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4dc4dbafd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7zTCvJkhkK7",
        "colab_type": "code",
        "outputId": "f01251fd-c084-4b25-f3e8-641616413e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "final_dataset.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 144 entries, 0 to 143\n",
            "Data columns (total 3 columns):\n",
            "transcript_id    144 non-null object\n",
            "text             144 non-null object\n",
            "label            144 non-null int64\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqx1f3HviLe6",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ms3ImLa_VPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'label':final_dataset.label, 'text':final_dataset.text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGcOF4k_X_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into training and transfer\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "# split data into training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlIJ9PAxIe3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.values.tolist()\n",
        "X_test = X_test.values.tolist()\n",
        "\n",
        "y_train = pd.get_dummies(y_train).values.tolist()\n",
        "y_test = pd.get_dummies(y_test).values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6smNk6ZAU2b",
        "colab_type": "code",
        "outputId": "a50c5af9-526d-44e6-8f0f-9becca9f1144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0],\n",
              " [0, 1],\n",
              " [1, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4V2DKqnAds",
        "colab_type": "text"
      },
      "source": [
        "# **Loading BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRiflTqeBs25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "package_dir = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
        "sys.path.append(package_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2Js9GxFChQ",
        "colab_type": "code",
        "outputId": "b0ebdba0-d6e9-4ad6-f579-e4fbc70ba89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.205)\n",
            "Collecting regex (from pytorch-pretrained-bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.205)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609229 sha256=8dae0930efbb95c704f08ba5652a1a5ca9c66c2f6704f5ae43d56943449f9274\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.8.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qHFNX5FEUA",
        "colab_type": "code",
        "outputId": "f842ef35-063e-4bf3-8f97-526b3a899bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "#import pytorch_pretrained_bert\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertForMaskedLM\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5)\n",
        "\n",
        "warnings.filterwarnings(action='once')\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:07<00:00, 56384519.05B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3doMeMFITS",
        "colab_type": "code",
        "outputId": "5e40ee65-c350-4598-f334-78851f570935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2460183.97B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w5K5SN0AwHc",
        "colab_type": "text"
      },
      "source": [
        "# **Preparing data for training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6t5TOCnKCc",
        "colab_type": "text"
      },
      "source": [
        "Now we create a class to preprocess data that involves tokenizing, truncating and padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8xKgazJ29_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "class text_dataset(Dataset):\n",
        "    def __init__(self,x_y_list, transform=None):\n",
        "        \n",
        "        self.x_y_list = x_y_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
        "        \n",
        "        if len(tokenized_review) > max_seq_length:\n",
        "            tokenized_review = tokenized_review[:max_seq_length]\n",
        "            \n",
        "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(ids_review))\n",
        "        \n",
        "        ids_review += padding\n",
        "        \n",
        "        assert len(ids_review) == max_seq_length\n",
        "        \n",
        "        #print(\"Hello\")\n",
        "        ids_review = torch.tensor(ids_review).long()\n",
        "        \n",
        "        sentiment = self.x_y_list[1][index] # color        \n",
        "        list_of_labels = [torch.from_numpy(np.array(sentiment)).long()]\n",
        "        \n",
        "        \n",
        "        return ids_review, list_of_labels[0]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_y_list[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQrQTCRrnZXt",
        "colab_type": "text"
      },
      "source": [
        "Preparing and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA3U816YksO_",
        "colab_type": "code",
        "outputId": "26632cf7-f4aa-4bd3-9ec6-67258111111c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_lists = [X_train, y_train]\n",
        "test_lists = [X_test, y_test]\n",
        "\n",
        "training_dataset = text_dataset(x_y_list = train_lists )\n",
        "\n",
        "test_dataset = text_dataset(x_y_list = test_lists )\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "                   }\n",
        "dataset_sizes = {'train':len(train_lists[0]),\n",
        "                'val':len(test_lists[0])}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUL5uFF5c_05",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2xL96andIXZ",
        "colab_type": "text"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVep1AogIndK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "        \n",
        "\n",
        "class BertForSequenceClassification(nn.Module):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary. Items in the batch should begin with the special \"CLS\" token. (see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller\n",
        "            than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, num_labels=2):\n",
        "        super(BertForSequenceClassification, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBh7tlgI1it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 2\n",
        "model = BertForSequenceClassification(num_labels)\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])\n",
        "\n",
        "#logits = model(tokens_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7B4rLMnFR4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    print('starting')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 100\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            sentiment_corrects = 0\n",
        "            \n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, sentiment in dataloaders_dict[phase]:\n",
        "                #print(\"ok till here\")\n",
        "                #inputs = inputs\n",
        "                #print(len(inputs),type(inputs),inputs)\n",
        "                #inputs = torch.from_numpy(np.array(inputs)).to(device) \n",
        "                inputs = inputs.to(device) \n",
        "\n",
        "                sentiment = sentiment.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        " \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #print(inputs)\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    outputs = F.softmax(outputs,dim = 1)\n",
        "                    \n",
        "                    \n",
        "                    loss = criterion(outputs, torch.max(sentiment.float(), 1)[1])\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        \n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                \n",
        "                sentiment_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(sentiment, 1)[1])\n",
        "\n",
        "                \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            \n",
        "            sentiment_acc = sentiment_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
        "            print('{} sentiment_acc: {:.4f}'.format(\n",
        "                phase, sentiment_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print('saving with loss of {}'.format(epoch_loss),\n",
        "                      'improved over previous {}'.format(best_loss))\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDoE-BzSH41N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "optim1 = optim.Adam(\n",
        "    [\n",
        "        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
        "        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
        "       \n",
        "   ])\n",
        "\n",
        "#optim1 = optim.Adam(model.parameters(), lr=0.001)#,momentum=.9)\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKcj7f5J0KM",
        "colab_type": "code",
        "outputId": "37e0eaa0-e5e3-4b7b-8afe-c56e63e6b127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.to(device)\n",
        "model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "Epoch 0/9\n",
            "----------\n",
            "train total loss: 0.5665 \n",
            "train sentiment_acc: 0.7478\n",
            "val total loss: 0.5547 \n",
            "val sentiment_acc: 0.7586\n",
            "saving with loss of 0.5546760949595221 improved over previous 100\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train total loss: 0.5134 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "saving with loss of 0.5546407432391726 improved over previous 0.5546760949595221\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "saving with loss of 0.5546407391285074 improved over previous 0.5546407432391726\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "saving with loss of 0.5546406733578649 improved over previous 0.5546407391285074\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "saving with loss of 0.5546406692471998 improved over previous 0.5546406733578649\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train total loss: 0.5133 \n",
            "train sentiment_acc: 0.8000\n",
            "val total loss: 0.5546 \n",
            "val sentiment_acc: 0.7586\n",
            "\n",
            "Training complete in 2m 21s\n",
            "Best val Acc: 0.554641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67OKez2ecjDg",
        "colab_type": "text"
      },
      "source": [
        "# **TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sP_L6Hz_ybT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#final_test = pd.read_csv('test.tsv',delimiter='\\t',encoding='utf-8')\n",
        "#X_final_test = final_test['Phrase']\n",
        "#X_final_test = X_final_test.values.tolist()\n",
        "X_final_test = ['I am depressed. I have distressing dreams. I have been exposed to violence. I have PTSD.','You are very kind', 'I have distressing dreams']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7TJU0QQeYxL",
        "colab_type": "text"
      },
      "source": [
        "Define a function to preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvT8bf2OtU_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "reviews=[]\n",
        "def test_dataset(Dataset):\n",
        "    for i in range(0,len(Dataset)):\n",
        "      tokenized_review = tokenizer.tokenize(Dataset[i])\n",
        "\n",
        "      if len(tokenized_review) > max_seq_length:\n",
        "          tokenized_review = tokenized_review[:max_seq_length]\n",
        "\n",
        "      ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "      padding = [0] * (max_seq_length - len(ids_review))\n",
        "\n",
        "      ids_review += padding\n",
        "\n",
        "      assert len(ids_review) == max_seq_length\n",
        "\n",
        "      #print(\"Hello\")\n",
        "      reviews.append(ids_review)\n",
        "\n",
        "    #sentiment = self.x_y_list[1][index] # color        \n",
        "    #list_of_labels = [torch.from_numpy(np.array(sentiment))]\n",
        "\n",
        "\n",
        "    return reviews#, list_of_labels[0]\n",
        "\n",
        "#def __len__(self):\n",
        " #   return len(self.x_list)\n",
        "X_final_test = test_dataset(X_final_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc5BXD-eun9",
        "colab_type": "text"
      },
      "source": [
        "Define the model and the configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn_REsL6c4Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "\n",
        "num_labels = 2\n",
        "model = BertForSequenceClassification(num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBCAQx5qe2Tn",
        "colab_type": "text"
      },
      "source": [
        "Load the previously saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfE191JybN1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('bert_model_test.pth'))\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()\n",
        "l = len(X_final_test)\n",
        "test_preds = np.zeros((l,num_labels))\n",
        "tests =  torch.utils.data.TensorDataset(torch.tensor(X_final_test))\n",
        "test_loader = torch.utils.data.DataLoader(tests, batch_size=l, shuffle=False)\n",
        "\n",
        "for i,(x_batch,)  in enumerate(test_loader):\n",
        "    t_preds = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    test_preds[i:i+l]=t_preds[:,0:num_labels].detach().cpu().squeeze().numpy()\n",
        "#test_preds = t_preds[:,0:23].detach().cpu().squeeze.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUYt2GnCfBUH",
        "colab_type": "text"
      },
      "source": [
        "Run our test list through the model and write the results to a file called test_preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxACSX5KhFb0",
        "colab_type": "code",
        "outputId": "be8024b1-ccbd-4129-d420-4ac775cb504a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "t_p = pd.DataFrame(test_preds)\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "test_preds1 = t_p.apply(lambda x:softmax(x), axis=1)\n",
        "test_preds1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999722</td>\n",
              "      <td>0.000278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998763</td>\n",
              "      <td>0.001237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.998014</td>\n",
              "      <td>0.001986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1\n",
              "0  0.999722  0.000278\n",
              "1  0.998763  0.001237\n",
              "2  0.998014  0.001986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YANaL0t0foAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_preds1).to_csv(\"test_preds1.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQHzO45lUCdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duviFKynUUTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}